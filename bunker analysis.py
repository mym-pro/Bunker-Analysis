import fitz
import re
import logging
import pandas as pd
from pathlib import Path
from datetime import datetime
import streamlit as st
import tempfile
from io import BytesIO
from github import Github
import base64
import requests

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.ERROR)
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

# å®šä¹‰æŒ‰é¡µç åˆ†ç»„çš„æ­£åˆ™è¡¨è¾¾å¼
EXTRACTION_CONFIG = {
    1: [  
        r"(MFSPD00)\s+(\d+\.\d+)",  
        r"(MFRDD00)\s+(\d+\.\d+)",  
        r"(MFHKD00)\s+(\d+\.\d+)",  
        r"(MFSAD00)\s+(\d+\.\d+)",  
        r"(MFZSD00)\s+\s*(\d+\.\d+)",  
    ],
    2: [  
        r"(MLBSO00)\s+(\d+\.\d+)",  
        r"(LNBSF00)\s+(\d+\.\d+)",  
    ]
}
DATE_PATTERN = r"Volume\s+\d+\s+/\s+Issue\s+\d+\s+/\s+(\w+\s+\d{1,2},\s+\d{4})"

# æ¸¯å£åæ˜ å°„
PORT_MAPPING = {
    "MFSPD00": "Singapore",
    "MFRDD00": "Rotterdam",
    "MFHKD00": "Hong Kong",
    "MFSAD00": "Santos",
    "MFZSD00": "Zhoushan"
}

class PDFDataExtractor:
    def __init__(self, pdf_path: Path):
        self.pdf_path = pdf_path

    def extract_data(self) -> pd.DataFrame:
        doc = fitz.open(self.pdf_path)  
        extracted_data = {}  
        date = None  

        for page_num in range(len(doc)):  
            page = doc.load_page(page_num)  
            text = page.get_text().strip()  

            if page_num == 0:  
                date_match = re.search(DATE_PATTERN, text)
                if date_match:
                    date_str = date_match.group(1)
                    date = datetime.strptime(date_str, "%B %d, %Y").date()
                    extracted_data["Date"] = date

            patterns = EXTRACTION_CONFIG.get(page_num + 1, [])  
            for pattern in patterns:  
                matches = re.findall(pattern, text)
                for match in matches:  
                    code, value = match
                    extracted_data[code] = float(value)

        doc.close()  

        desired_order = [
            "Date",
            "MFSPD00", "MFRDD00", "MFHKD00", "MFSAD00", "MFZSD00", "MLBSO00", "LNBSF00"
        ]
        sorted_data = {key: extracted_data.get(key) for key in desired_order}  
        return pd.DataFrame([sorted_data])  

class GitHubDataSaver:
    def __init__(self, repo_name: str, file_path: str, github_token: str):
        self.repo_name = repo_name
        self.file_path = file_path
        self.github_token = github_token

    def save_data(self, df: pd.DataFrame):
        if df.empty:
            return

        df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')
        current_date = df['Date'].iloc[0]

        try:
            # è¿æ¥åˆ°GitHub
            g = Github(self.github_token)
            repo = g.get_repo(self.repo_name)
            
            # å°è¯•è·å–ç°æœ‰æ–‡ä»¶
            try:
                contents = repo.get_contents(self.file_path)
                existing_data = pd.read_excel(BytesIO(base64.b64decode(contents.content)), engine='openpyxl')
                if current_date in existing_data['Date'].tolist():
                    st.warning(f"æ•°æ®æ—¥æœŸ {current_date} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¿å­˜ã€‚")
                    return
                combined_df = pd.concat([existing_data, df])
            except Exception as e:
                # æ–‡ä»¶ä¸å­˜åœ¨æ—¶åˆ›å»ºæ–°æ–‡ä»¶
                combined_df = df

            # å¤„ç†æ•°æ®
            combined_df = combined_df.sort_values(by='Date', ascending=True)
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                combined_df.to_excel(writer, index=False)
            excel_data = output.getvalue()

            # æäº¤åˆ°GitHub
            if 'contents' in locals():
                repo.update_file(contents.path, f"æ›´æ–°æ•°æ® {datetime.today().date()}", excel_data, contents.sha)
            else:
                repo.create_file(self.file_path, "åˆå§‹æ•°æ®æäº¤", excel_data)
            
            st.success("æ•°æ®å·²ä¿å­˜åˆ°GitHubä»“åº“ï¼")
        except Exception as e:
            logger.error(f"ä¿å­˜å¤±è´¥: {str(e)}")
            st.error(f"ä¿å­˜æ•°æ®æ—¶å‡ºé”™: {str(e)}")

def main_ui():
    st.set_page_config(page_title="PDF æ•°æ®æå–å™¨", layout="wide")
    st.title("PDF æ•°æ®æå–å™¨")

    # ä»Secretsè·å–GitHubé…ç½®
    try:
        github_token = st.secrets.github.token
        repo_name = st.secrets.github.repo
        file_path = "history_data/extracted_data.xlsx"
    except Exception as e:
        st.error("è¯·æ­£ç¡®é…ç½®GitHub Secretsï¼")
        return

    # æ–‡ä»¶ä¸Šä¼ æ¨¡å—
    with st.expander("ğŸ“¤ ç¬¬ä¸€æ­¥ - ä¸Šä¼ PDFæ–‡ä»¶", expanded=True):
        uploaded_file = st.file_uploader("é€‰æ‹©PDFæ–‡ä»¶", type=["pdf"])

    if uploaded_file:
        current_file_hash = hash(uploaded_file.getvalue())
        if 'last_file_hash' not in st.session_state or st.session_state.last_file_hash != current_file_hash:
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                    tmp.write(uploaded_file.getvalue())
                    pdf_path = Path(tmp.name)

                extractor = PDFDataExtractor(pdf_path)
                extracted_df = extractor.extract_data()

                saver = GitHubDataSaver(repo_name, file_path, github_token)
                saver.save_data(extracted_df)

                st.session_state.last_file_hash = current_file_hash
                st.success("æ•°æ®æå–æˆåŠŸï¼")
            except Exception as e:
                logger.error(f"å¤„ç†å¤±è´¥: {str(e)}")
                st.error(f"æ–‡ä»¶å¤„ç†é”™è¯¯: {str(e)}")

    # æ•°æ®å±•ç¤ºæ¨¡å—
    with st.expander("ğŸ“ˆ ç¬¬äºŒæ­¥ - æ•°æ®å±•ç¤º", expanded=True):
        try:
            # ä»GitHubè·å–æ•°æ®
            g = Github(github_token)
            repo = g.get_repo(repo_name)
            contents = repo.get_contents(file_path)
            data_df = pd.read_excel(BytesIO(base64.b64decode(contents.content)), engine='openpyxl')
            data_df['Date'] = pd.to_datetime(data_df['Date']).dt.strftime('%Y-%m-%d')
            data_df = data_df.sort_values(by='Date', ascending=False)
            
            # å±•ç¤ºå†…å®¹ä¸€ï¼šå±•ç¤º"MFSPD00", "MFRDD00", "MFHKD00", "MFSAD00", "MFZSD00"çš„æœ€æ–°åæ¡æ•°æ®
            st.subheader("æœ€æ–°åæ¡æ¸¯å£æ•°æ®")
            latest_data = data_df[["Date", "MFSPD00", "MFRDD00", "MFHKD00", "MFSAD00", "MFZSD00"]].head(10)
            latest_data_renamed = latest_data.rename(columns=PORT_MAPPING)
            st.table(latest_data_renamed.set_index("Date"))

            # å±•ç¤ºå†…å®¹äºŒï¼šå±•ç¤º"MLBSO00", "LNBSF00"çš„æœ€æ–°åæ¡æ•°æ®
            st.subheader("æœ€æ–°åæ¡ MLBSO00 å’Œ LNBSF00 æ•°æ®")
            latest_data_mlbs = data_df[["Date", "MLBSO00", "LNBSF00"]].head(10)
            latest_data_mlbs = latest_data_mlbs.sort_values(by='Date', ascending=True)
            st.table(latest_data_mlbs.set_index("Date"))

            # å±•ç¤ºå†…å®¹ä¸‰ï¼šé€‰å®šä¸¤ä¸ªæ—¥æœŸè¿›è¡Œæ¯”è¾ƒ
            st.subheader("æ—¥æœŸæ•°æ®å˜åŠ¨æ¯”è¾ƒ")
            date_options = data_df['Date'].unique()
            selected_dates = st.multiselect("é€‰æ‹©ä¸¤ä¸ªæ—¥æœŸè¿›è¡Œæ¯”è¾ƒ", options=date_options, max_selections=2)
            if len(selected_dates) == 2:
                date1, date2 = selected_dates
                data1 = data_df[data_df['Date'] == date1][["MFSPD00", "MFRDD00", "MFHKD00", "MFSAD00", "MFZSD00"]]
                data2 = data_df[data_df['Date'] == date2][["MFSPD00", "MFRDD00", "MFHKD00", "MFSAD00", "MFZSD00"]]
                comparison_df = pd.DataFrame({
                    "æ¸¯å£": ["Singapore", "Rotterdam", "Hong Kong", "Santos", "Zhoushan"],
                    f"{date1}": data1.iloc[0].values,
                    f"{date2}": data2.iloc[0].values,
                    "ç¯æ¯”å˜åŒ– (%)": ((data1.iloc[0].values - data2.iloc[0].values) / data2.iloc[0].values * 100).round(2)
                })
                st.table(comparison_df.set_index("æ¸¯å£"))

        except Exception as e:
            st.warning("æš‚æ— å†å²æ•°æ®æˆ–è¯»å–å¤±è´¥")

    # æ•°æ®å¯¼å‡ºæ¨¡å—
    with st.expander("ğŸ“¥ ç¬¬ä¸‰æ­¥ - æ•°æ®å¯¼å‡º", expanded=True):
        try:
            contents = repo.get_contents(file_path)
            data_df = pd.read_excel(BytesIO(base64.b64decode(contents.content)), engine='openpyxl')
            
            # æ•°æ®æŒ‰æ—¥æœŸå‡åºæ’åˆ—
            data_df = data_df.sort_values(by='Date', ascending=True)
            
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                data_df.to_excel(writer, index=False)
            st.download_button(
                label="ä¸‹è½½å®Œæ•´æ•°æ®",
                data=output.getvalue(),
                file_name="complete_data.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        except Exception as e:
            st.warning("æš‚æ— æ•°æ®å¯ä¾›å¯¼å‡º")

if __name__ == "__main__":
    main_ui()
