import streamlit as st
import fitz  # PyMuPDF
import pandas as pd
import os
import re
import logging
import tempfile
import time
from pathlib import Path
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from github import Github
import base64
from io import BytesIO

# --------------------------
# é…ç½®æ—¥å¿—ç³»ç»Ÿ
# --------------------------
logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger(__name__)

# --------------------------
# å¸¸é‡å®šä¹‰ï¼ˆæ–°å¢éƒ¨åˆ†ï¼‰
# --------------------------
PORT_CODE_MAPPING = {
    # Asia Pacific/Middle East
    "MFSPD00": "Singapore", "MFFJD00": "Fujairah", "MFJPD00": "Japan",
    "BAMFB00": "West Japan", "MFSKD00": "South Korea", "WKMFA00": "South Korea (West)",
    "MFHKD00": "Hong Kong", "MFSHD00": "Shanghai", "MFZSD00": "Zhoushan",
    "MFDSY00": "Sydney", "MFDMB00": "Melbourne", "MFDKW00": "Kuwait",
    "MFDKF00": "Khor Fakkan", "MFDMM00": "Mumbai", "MFDCL00": "Colombo",
    # Europe
    "MFAGD00": "Algeciras", "MFDBD00": "Durban", "MFGBD00": "Gibraltar",
    "MFMLD00": "Malta", "MFPRD00": "Piraeus", "MFRDD00": "Rotterdam",
    "MFDAN00": "Antwerp", "MFDGT00": "Gothenburg", "MFDHB00": "Hamburg",
    "MFDIS00": "Istanbul", "MFDLP00": "Las Palmas", "MFDNV00": "Novorossiisk",
    "MFDPT00": "St. Petersburg", "MFLIS00": "Lisbon", "MFLOM00": "Lome",
    # Americas
    "MFHOD00": "Houston", "MFNYD00": "New York", "MFLAD00": "Los Angeles",
    "MFNOD00": "New Orleans", "MFPAD00": "Philadelphia", "MFSED00": "Seattle",
    "MFVAD00": "Vancouver", "MFBAD00": "Buenos Aires", "MFCRD00": "Cartagena",
    "MFSAD00": "Santos", "AMFVA00": "Valparaiso", "AMFCA00": "Callao",
    "AMFGY00": "Guayaquil", "AMFLB00": "La Libertad", "AMFMT00": "Montevideo",
    "AMFSF00": "San Francisco", "AMFMO00": "Montreal*"
}

REGION_CODE_ORDER = [
    ("Asia Pacific/Middle East", [
        "MFSPD00", "MFFJD00", "MFJPD00", "BAMFB00", "MFSKD00",
        "WKMFA00", "MFHKD00", "MFSHD00", "MFZSD00", "MFDSY00",
        "MFDMB00", "MFDKW00", "MFDKF00", "MFDMM00", "MFDCL00"
    ]),
    ("Europe", [
        "MFAGD00", "MFDBD00", "MFGBD00", "MFMLD00", "MFPRD00",
        "MFRDD00", "MFDAN00", "MFDGT00", "MFDHB00", "MFDIS00",
        "MFDLP00", "MFDNV00", "MFDPT00", "MFLIS00", "MFLOM00"
    ]),
    ("Americas", [
        "MFHOD00", "MFNYD00", "MFLAD00", "MFNOD00", "MFPAD00",
        "MFSED00", "MFVAD00", "MFBAD00", "MFCRD00", "MFSAD00",
        "AMFVA00", "AMFCA00", "AMFGY00", "AMFLB00", "AMFMT00",
        "AMFSF00", "AMFMO00"
    ])
]

TAB1_COLUMN_ORDER = [
    "AMFSA00", "MFSPD00", "PPXDK00", "PUAFT00", "AAXYO00",
    "PUMFD00", "MFRDD00", "PUABC00", "PUAFN00", "AARTG00",
    "MFSAD00", "AAXWO00", "MFZSD00", "BFDZA00", "MGZSD00",
    "MFHKD00", "PUAER00", "AAXYQ00", "MFSKD00", "PUAGQ00",
    "AAXYS00", "MFSHD00", "AARKD00", "AAXYR00", "MFGBD00",
    "AAKAB00", "AARSU00", "MFNOD00", "AAGQE00", "AAWYA00",
    "AMFFA00", "MFFJD00", "PUAXP00", "AAXYP00"
]

FUEL_TYPE_MAPPING = {
    "MLBSO00": "MEOH-SG",
    "LNBSF00": "LNG-SG"
}

# --------------------------
# æ•°æ®å¤„ç†å·¥å…·ç±»ï¼ˆä¿®æ”¹éƒ¨åˆ†ï¼‰
# --------------------------
class BunkerDataProcessor:
    @staticmethod
    def format_date(date_series: pd.Series) -> pd.Series:
        # å¢å¼ºæ—¥æœŸå¤„ç†é€»è¾‘
        return pd.to_datetime(
            date_series,
            errors='coerce',  # å°†æ— æ•ˆæ—¥æœŸè½¬ä¸ºNaT
            format='mixed'    # è‡ªåŠ¨è¯†åˆ«å¤šç§æ—¥æœŸæ ¼å¼
        ).dt.date

    @staticmethod
    def clean_dataframe(df: pd.DataFrame, data_type: str = "bunker") -> pd.DataFrame:
        if df.empty:
            return df

        # ç»Ÿä¸€æ—¥æœŸæ ¼å¼ï¼ˆå¢å¼ºå¤„ç†ï¼‰
        if 'Date' in df.columns:
            # å…ˆè½¬æ¢ä¸ºdatetimeç±»å‹
            df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
            # è¿‡æ»¤æ— æ•ˆæ—¥æœŸ
            df = df[df['Date'].notna()]
            # è½¬æ¢ä¸ºdateç±»å‹
            df['Date'] = df['Date'].dt.date

        # æŒ‰æ•°æ®ç±»å‹å¤„ç†åˆ—é¡ºåº
        if data_type == "bunker":
            all_ports = [PORT_CODE_MAPPING.get(code, code) for code in TAB1_COLUMN_ORDER if code in df.columns]
            ordered_columns = ['Date'] + all_ports
            df = df.reindex(columns=ordered_columns, fill_value=pd.NA)
        elif data_type == "regional":
            ordered_columns = ['Date']
            for _, codes in REGION_CODE_ORDER:
                ordered_columns.extend([PORT_CODE_MAPPING[code] for code in codes if code in df.columns])
            df = df.reindex(columns=ordered_columns, fill_value=pd.NA)
        elif data_type == "fuel":
            ordered_columns = ['Date'] + list(FUEL_TYPE_MAPPING.values())
            df = df.rename(columns=FUEL_TYPE_MAPPING)
            df = df.reindex(columns=ordered_columns, fill_value=pd.NA)

        # å»é‡æ’åº
        df = df.drop_duplicates()
        df = df.sort_values('Date', ascending=True)
        return df.reset_index(drop=True)

    @staticmethod
    def merge_data(existing_df: pd.DataFrame, new_df: pd.DataFrame, data_type: str) -> pd.DataFrame:
        combined = pd.concat([existing_df, new_df])
        return BunkerDataProcessor.clean_dataframe(combined, data_type)

# --------------------------
# GitHubæ•°æ®ç®¡ç†å™¨ï¼ˆä¿®æ”¹éƒ¨åˆ†ï¼‰
# --------------------------
class GitHubDataManager:
    def __init__(self, token: str, repo_name: str):
        self.token = token
        self.repo_name = repo_name
        self.g = Github(self.token)
        self.repo = self.g.get_repo(self.repo_name)

    def read_excel(self, file_path: str, data_type: str) -> Tuple[pd.DataFrame, bool]:
        try:
            contents = self.repo.get_contents(file_path)
            df = pd.read_excel(BytesIO(base64.b64decode(contents.content)), sheet_name=0)
            return BunkerDataProcessor.clean_dataframe(df, data_type), True
        except Exception as e:
            return pd.DataFrame(), False

    def save_excel(self, df: pd.DataFrame, file_path: str, commit_msg: str, data_type: str) -> bool:
        try:
            # ç¡®ä¿è·¯å¾„å­˜åœ¨
            dir_path = os.path.dirname(file_path)
            if dir_path:
                try:
                    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
                    self.repo.get_contents(dir_path)
                except Exception as e:
                    # åˆ›å»ºç›®å½•
                    self.repo.create_file(
                        path=f"{dir_path}/.gitkeep",
                        message=f"Create directory {dir_path}",
                        content=""
                    )
            # æŒ‰æ•°æ®ç±»å‹å¤„ç†åˆ—é¡ºåº
            processed_df = BunkerDataProcessor.clean_dataframe(df, data_type)
            
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                processed_df.to_excel(writer, index=False)
            content = output.getvalue()
            
            try:
                contents = self.repo.get_contents(file_path)
                self.repo.update_file(contents.path, commit_msg, content, contents.sha)
            except:
                self.repo.create_file(file_path, commit_msg, base64.b64encode(content).decode())
            return True
        except Exception as e:
            logger.error(f"GitHubä¿å­˜å¤±è´¥: {str(e)}")
            return False

# --------------------------
# PDFæ•°æ®æå–å™¨ï¼ˆä¿®æ”¹åçš„ç‰ˆæœ¬ï¼Œç»“åˆä»£ç 1çš„åŒºåŸŸåˆ’åˆ†é€»è¾‘ï¼‰
# --------------------------
class EnhancedBunkerPriceExtractor:
    def __init__(self, pdf_path: str, bunker_path: str, fuel_path: str):
        self.pdf_path = pdf_path
        self.bunker_path = bunker_path
        self.fuel_path = fuel_path

    def process_pdf(self) -> Dict[str, int]:
        try:
            doc = fitz.open(self.pdf_path)
            result = {'bunker': 0, 'fuel': 0}
            
            # å¤„ç†ç¬¬ä¸€é¡µï¼ˆæ²¹ä»·æ•°æ®ï¼‰
            bunker_df = self._process_bunker_page(doc[0])
            if bunker_df is not None:
                success = self._save_data(bunker_df, self.bunker_path, "bunker")
                result['bunker'] = len(bunker_df) if success else 0

            # å¤„ç†ç¬¬äºŒé¡µï¼ˆç‡ƒæ–™æ•°æ®ï¼‰
            fuel_df = self._process_fuel_page(doc[1])
            if fuel_df is not None:
                success = self._save_data(fuel_df, self.fuel_path, "fuel")
                result['fuel'] = len(fuel_df) if success else 0

            doc.close()
            return result
        except Exception as e:
            logger.error(f"PDFå¤„ç†å¤±è´¥: {str(e)}")
            return {'bunker': 0, 'fuel': 0}

    def _get_page_coordinates(self, page, config: Dict) -> Optional[Dict]:
        """è·å–é¡µé¢å…³é”®åŒºåŸŸåæ ‡"""
        blocks = page.get_text("blocks")
        coords = {
            'start_y': None,
            'end_y': None,
            'left_x': 0,
            'right_x': page.rect.width
        }

        for block in blocks:
            text = block[4].strip()
            # å®šä½èµ·å§‹ä½ç½®
            if config['start_key'] in text and coords['start_y'] is None:
                coords['start_y'] = block[1]
            # å®šä½ç»“æŸä½ç½®
            if config['end_key'] in text and coords['end_y'] is None:
                coords['end_y'] = block[1]
            # å³ä¾§è¾¹ç•Œ
            if 'right_boundary' in config and config['right_boundary'] in text:
                coords['right_x'] = block[0]
            # å·¦ä¾§è¾¹ç•Œ
            if 'left_boundary' in config and config['left_boundary'] in text:
                coords['left_x'] = block[2]

        if None in [coords['start_y'], coords['end_y']]:
            logger.warning(f"é¡µé¢åæ ‡å®šä½å¤±è´¥: {config}")
            return None
        return coords

    def _extract_text_from_area(self, page, coords: Dict) -> str:
        """ä»æŒ‡å®šåŒºåŸŸæå–æ–‡æœ¬"""
        rect = fitz.Rect(
            coords['left_x'],
            min(coords['start_y'], coords['end_y']),
            coords['right_x'],
            max(coords['start_y'], coords['end_y'])
        )
        return page.get_text("text", clip=rect)

    def _process_bunker_page(self, page) -> Optional[pd.DataFrame]:
        # å®šä¹‰é¡µé¢è§£æé…ç½®
        coord_config = {
            'start_key': 'Bunkerwire',
            'end_key': 'Ex-Wharf',
            'right_boundary': 'Marine Fuel (PGB page 30)'
        }
        coords = self._get_page_coordinates(page, coord_config)
        if not coords:
            return None

        # æå–æŒ‡å®šåŒºåŸŸçš„æ–‡æœ¬
        raw_text = self._extract_text_from_area(page, coords)
        if not raw_text:
            return None

        date = self._extract_date(raw_text)
        if not date:
            return None

        # ä½¿ç”¨ç²¾ç¡®æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
        pattern = re.compile(r"([A-Z]{6,8}00)\s+(\d+\.\d+|NA)\s+([+-]?\d+\.\d+|NANA)")
        matches = pattern.findall(raw_text)
        if not matches:
            return None

        # æ„å»ºæ•°æ®å­—å…¸
        data = {'Date': [date]}
        for code, price, _ in matches:
            if price != 'NA' and code in PORT_CODE_MAPPING:
                port = PORT_CODE_MAPPING[code]
                data[port] = [float(price)]

        return pd.DataFrame(data)

    def _process_fuel_page(self, page) -> Optional[pd.DataFrame]:
        # å®šä¹‰é¡µé¢è§£æé…ç½®
        coord_config = {
            'start_key': 'Alternative marine fuels',
            'end_key': 'Arab Gulf'
        }
        coords = self._get_page_coordinates(page, coord_config)
        if not coords:
            return None

        # æå–æŒ‡å®šåŒºåŸŸçš„æ–‡æœ¬
        raw_text = self._extract_text_from_area(page, coords)
        if not raw_text:
            return None

        date = self._extract_date(raw_text)
        if not date:
            return None

        pattern = re.compile(r"(MLBSO00|LNBSF00)\s+(\d+\.\d+|NA)")
        matches = pattern.findall(raw_text)
        if not matches:
            return None

        data = {'Date': [date]}
        for code, price in matches:
            if price != 'NA':
                data[code] = [float(price)]
        return pd.DataFrame(data)

    def _extract_date(self, text: str) -> Optional[datetime.date]:
        date_pattern = r"Volume\s+\d+\s+/\s+Issue\s+\d+\s+/\s+(\w+\s+\d{1,2},\s+\d{4})"
        match = re.search(date_pattern, text)
        if match:
            try:
                return datetime.strptime(match.group(1), "%B %d, %Y").date()
            except ValueError:
                pass
        return None

    def _save_data(self, new_df: pd.DataFrame, output_path: str, data_type: str) -> bool:
        try:
            github_token = st.secrets.github.token
            repo_name = st.secrets.github.repo
            gh_manager = GitHubDataManager(github_token, repo_name)
            
            existing_df, exists = gh_manager.read_excel(output_path, data_type)
            if exists:
                combined_df = BunkerDataProcessor.merge_data(existing_df, new_df, data_type)
            else:
                combined_df = BunkerDataProcessor.clean_dataframe(new_df, data_type)
                
            return gh_manager.save_excel(combined_df, output_path, 
                                      f"Update {data_type} data", 
                                      data_type)
        except Exception as e:
            logger.error(f"ä¿å­˜å¤±è´¥: {str(e)}")
            return False

# --------------------------
# Streamlitç•Œé¢
# --------------------------
@st.cache_data(ttl=3600, show_spinner="åŠ è½½å†å²æ•°æ®...")
def load_history_data(path: str, data_type: str) -> pd.DataFrame:
    try:
        github_token = st.secrets.github.token
        repo_name = st.secrets.github.repo
        gh_manager = GitHubDataManager(github_token, repo_name)
        df, exists = gh_manager.read_excel(path, data_type)
        return df if exists else pd.DataFrame()
    except Exception as e:
        logger.error(f"æ•°æ®åŠ è½½å¤±è´¥: {path} - {str(e)}")
        return pd.DataFrame()

def generate_excel_download(df: pd.DataFrame) -> bytes:
    """å¢å¼ºçš„ç©ºæ•°æ®æ ¡éªŒ"""
    if df.empty:
        raise ValueError("æ— æ³•å¯¼å‡ºç©ºæ•°æ®é›†")
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False)
    output.seek(0)
    return output.getvalue()

def on_download_click(success: bool, filename: str):
    """ä¸‹è½½çŠ¶æ€æç¤º"""
    if success:
        st.toast(f"âœ… {filename} å¼€å§‹ä¸‹è½½ï¼Œè¯·æŸ¥çœ‹æµè§ˆå™¨ä¸‹è½½åˆ—è¡¨")
    else:
        st.toast(f"âš ï¸ ä¸‹è½½æ–‡ä»¶ç”Ÿæˆå¤±è´¥", icon="âš ï¸")

def main_ui():
    st.set_page_config(page_title="èˆ¹ç‡ƒä»·æ ¼åˆ†æç³»ç»Ÿ", layout="wide")
    st.title("Mariners' Bunker Price Analysis System")

    # åˆå§‹åŒ–è·¯å¾„
    BUNKER_PATH = "data/bunker_prices.xlsx"
    FUEL_PATH = "data/fuel_prices.xlsx"

    # åˆå§‹åŒ–sessionçŠ¶æ€
    if 'processed_files' not in st.session_state:
        st.session_state.processed_files = set()

    # æ–‡ä»¶ä¸Šä¼ æ¨¡å—
    with st.expander("ğŸ“¤ ç¬¬ä¸€æ­¥ - ä¸Šä¼ PDFæŠ¥å‘Š", expanded=True):
        uploaded_files = st.file_uploader(
            "é€‰æ‹©Bunkerwire PDFæŠ¥å‘Šï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
            type=["pdf"],
            accept_multiple_files=True
        )

    # å¤„ç†æ–°æ–‡ä»¶
    new_files = [f for f in uploaded_files if f.name not in st.session_state.processed_files]
    if new_files:
        with st.status("æ­£åœ¨è§£ææ–‡ä»¶...", expanded=True) as status:
            progress_bar = st.progress(0)
            total_files = len(new_files)
            total_added = {'bunker': 0, 'fuel': 0}
            
            for idx, file in enumerate(new_files):
                try:
                    # æ˜¾ç¤ºå¤„ç†è¿›åº¦
                    progress_bar.progress((idx+1)/total_files, text=f"æ­£åœ¨å¤„ç† {file.name} ({idx+1}/{total_files})")
                    
                    with tempfile.NamedTemporaryFile(delete=False) as tmp:
                        tmp.write(file.getbuffer())
                        extractor = EnhancedBunkerPriceExtractor(tmp.name, BUNKER_PATH, FUEL_PATH)
                        result = extractor.process_pdf()
                        total_added['bunker'] += result['bunker']
                        total_added['fuel'] += result['fuel']
                        st.session_state.processed_files.add(file.name)
                    os.unlink(tmp.name)
                    
                    # å®æ—¶æ˜¾ç¤ºå¤„ç†ç»“æœ
                    st.write(f"âœ… {file.name} å¤„ç†å®Œæˆ (æ²¹ä»·+{result['bunker']}, ç‡ƒæ–™+{result['fuel']})")
                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥ {file.name}: {str(e)}")
            
            status.update(label=f"å¤„ç†å®Œæˆï¼å…±æ–°å¢æ²¹ä»·{total_added['bunker']}æ¡ï¼Œç‡ƒæ–™{total_added['fuel']}æ¡", state="complete")
            st.cache_data.clear()

    # æ•°æ®åˆ†ææ¨¡å—
    bunker_df = load_history_data(BUNKER_PATH, "bunker")
    fuel_df = load_history_data(FUEL_PATH, "fuel")

    with st.expander("ğŸ“ˆ ç¬¬äºŒæ­¥ - æ•°æ®åˆ†æ", expanded=True):
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "æŒ‡å®šæ ¼å¼æ²¹ä»·", "åŒºåŸŸæ²¹ä»·", "ç‡ƒæ–™ä»·æ ¼", "è¶‹åŠ¿åˆ†æ", "æ•°æ®å¯¹æ¯”"
        ])

        # Tab1 - æŒ‡å®šæ ¼å¼æ²¹ä»·
        with tab1:
            if not bunker_df.empty:
                st.subheader("æ ‡å‡†æ ¼å¼æ²¹ä»·æ•°æ®")
                
                # ç”Ÿæˆæ˜¾ç¤ºç”¨æ•°æ®
                display_cols = ['Date'] + [
                    PORT_CODE_MAPPING.get(code, code) 
                    for code in TAB1_COLUMN_ORDER 
                    if PORT_CODE_MAPPING.get(code, code) in bunker_df.columns
                ]
                display_df = bunker_df[display_cols].sort_values('Date', ascending=False)
                
                st.dataframe(
                    display_df,
                    use_container_width=True,
                    height=600
                )
                
                # ä¸‹è½½æŒ‰é’®
                col1, col2 = st.columns(2)
                with col1:
                    st.download_button(
                        "ä¸‹è½½å®Œæ•´æ•°æ®",
                        data=generate_excel_download(bunker_df[display_cols].sort_values('Date')),
                        file_name="standard_bunker.xlsx"
                    )
                with col2:
                    selected_date = st.selectbox("é€‰æ‹©æ—¥æœŸ", bunker_df['Date'].unique())
                    st.download_button(
                        "ä¸‹è½½å•æ—¥æ•°æ®",
                        data=generate_excel_download(
                            bunker_df[bunker_df['Date'] == selected_date][display_cols]),
                        file_name=f"standard_bunker_{selected_date}.xlsx"
                    )

        # Tab2 - åŒºåŸŸæ²¹ä»·
        with tab2:
            if not bunker_df.empty:
                st.subheader("åŒºåŸŸæ²¹ä»·æ•°æ®")
                
                # ç”ŸæˆåŒºåŸŸæ•°æ®
                for region_name, codes in REGION_CODE_ORDER:
                    port_names = [PORT_CODE_MAPPING[code] for code in codes if code in bunker_df.columns]
                    if port_names:
                        with st.expander(region_name, expanded=True):
                            region_df = bunker_df[['Date'] + port_names].sort_values('Date', ascending=False)
                            st.dataframe(region_df, height=300)
                
                # ä¸‹è½½æŒ‰é’®
                full_cols = ['Date']
                for _, codes in REGION_CODE_ORDER:
                    full_cols.extend([PORT_CODE_MAPPING[code] for code in codes if code in bunker_df.columns])
                
                col1, col2 = st.columns(2)
                with col1:
                    st.download_button(
                        "ä¸‹è½½å®Œæ•´åŒºåŸŸæ•°æ®",
                        data=generate_excel_download(bunker_df[full_cols].sort_values('Date')),
                        file_name="regional_bunker.xlsx"
                    )
                with col2:
                    selected_date = st.selectbox("é€‰æ‹©æ—¥æœŸ", bunker_df['Date'].unique(), key="region_date")
                    st.download_button(
                        "ä¸‹è½½å•æ—¥åŒºåŸŸæ•°æ®",
                        data=generate_excel_download(
                            bunker_df[bunker_df['Date'] == selected_date][full_cols]),
                        file_name=f"regional_bunker_{selected_date}.xlsx"
                    )

        with tab3:
            if not fuel_df.empty:
                st.subheader("æ›¿ä»£ç‡ƒæ–™ä»·æ ¼è¶‹åŠ¿")
                
                # è½¬æ¢åˆ—åä¸ºå‹å¥½åç§°
                fuel_display_df = fuel_df.rename(columns=FUEL_TYPE_MAPPING)
                
                # æ˜¾ç¤ºæœ€æ–°10æ¡æ•°æ®ï¼ˆæœ€æ–°æ—¥æœŸåœ¨ä¸Šï¼‰
                st.dataframe(
                    fuel_display_df.sort_values('Date', ascending=False).head(10),
                    use_container_width=True,
                    height=300
                )
                
                # è¶‹åŠ¿å›¾
                fig = go.Figure()
                for fuel_type in FUEL_TYPE_MAPPING.values():
                    if fuel_type in fuel_display_df.columns:
                        fig.add_trace(go.Scatter(
                            x=fuel_display_df['Date'],
                            y=fuel_display_df[fuel_type],
                            name=fuel_type,
                            mode='lines+markers',
                            connectgaps=True
                        ))
                fig.update_layout(
                    title="æ›¿ä»£ç‡ƒæ–™ä»·æ ¼è¶‹åŠ¿",
                    xaxis_title="æ—¥æœŸ",
                    yaxis_title="ä»·æ ¼ (USD)",
                    template="plotly_white"
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # ä¸‹è½½é€»è¾‘
                col1, col2 = st.columns(2)
                with col1:
                    st.download_button(
                        label="ä¸‹è½½å®Œæ•´ç‡ƒæ–™æ•°æ®",
                        data=generate_excel_download(fuel_display_df.sort_values('Date')),
                        file_name="fuel_prices_full.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                with col2:
                    selected_date = st.selectbox(
                        "é€‰æ‹©ç‡ƒæ–™æ—¥æœŸ",
                        options=sorted(fuel_df['Date'].astype(str).unique(), reverse=True),
                        key="fuel_date"
                    )
                    st.download_button(
                        label="ä¸‹è½½å•æ—¥ç‡ƒæ–™æ•°æ®",
                        data=generate_excel_download(
                            fuel_display_df[fuel_display_df['Date'].astype(str) == selected_date]
                        ),
                        file_name=f"fuel_{selected_date}.xlsx"
                    )
            else:
                st.warning("æš‚æ— ç‡ƒæ–™æ•°æ®")

        # Tab4 - è¶‹åŠ¿åˆ†æï¼ˆåŸTAB3ï¼‰
        with tab4:
            if not bunker_df.empty:
                # æ·»åŠ ç±»å‹è½¬æ¢ç¡®ä¿Dateåˆ—æ˜¯datetimeç±»å‹
                bunker_df['Date'] = pd.to_datetime(bunker_df['Date'], errors='coerce')
                bunker_df = bunker_df.dropna(subset=['Date'])
                
                st.subheader("å¤šæ¸¯å£è¶‹åŠ¿å¯¹æ¯”åˆ†æ")
                
                # æ§ä»¶å¸ƒå±€
                col1, col2, col3 = st.columns([3, 2, 1])
                with col1:
                    # æŒ‰åŒºåŸŸåˆ†ç»„é€‰æ‹©æ¸¯å£
                    selected_ports = []
                    for region_name, codes in REGION_CODE_ORDER:
                        port_names = [PORT_CODE_MAPPING[code] for code in codes 
                                    if PORT_CODE_MAPPING[code] in bunker_df.columns]
                        if port_names:
                            selected = st.multiselect(
                                f"{region_name} æ¸¯å£",
                                options=port_names,
                                default=port_names[:1] if region_name == "Asia Pacific/Middle East" else []
                            )
                            selected_ports.extend(selected)
                with col2:
                    # ä¿®æ”¹å¹´ä»½è·å–æ–¹å¼
                    if not bunker_df.empty:
                        bunker_df['Year'] = bunker_df['Date'].dt.year  # ç°åœ¨å¯ä»¥å®‰å…¨ä½¿ç”¨.dt
                        year_options = sorted(bunker_df['Year'].unique(), reverse=True)
                        selected_year = st.selectbox("é€‰æ‹©å¹´ä»½", year_options)
                with col3:
                    st.markdown("###")
                    show_annotations = st.checkbox("æ˜¾ç¤ºæ•°æ®ç‚¹", value=True)
                
                # æ•°æ®å¤„ç†
                filtered_df = bunker_df[bunker_df['Year'] == selected_year]
                if selected_ports:
                    # åˆ›å»ºè¶‹åŠ¿å›¾
                    fig = go.Figure()
                    for port in selected_ports:
                        valid_data = filtered_df[['Date', port]].dropna()
                        if not valid_data.empty:
                            fig.add_trace(go.Scatter(
                                x=valid_data['Date'],
                                y=valid_data[port],
                                name=port,
                                mode='lines+markers' if show_annotations else 'lines',
                                visible=True
                            ))
                    
                    # å›¾è¡¨å¸ƒå±€
                    fig.update_layout(
                        title=f"{selected_year}å¹´æ²¹ä»·è¶‹åŠ¿åˆ†æ",
                        xaxis_title="æ—¥æœŸ",
                        yaxis_title="ä»·æ ¼ (USD)",
                        legend=dict(orientation="h", yanchor="bottom", y=1.02),
                        hovermode="x unified",
                        height=600
                    )
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¸¯å£è¿›è¡Œå¯¹æ¯”")
            else:
                st.warning("æš‚æ— æ²¹ä»·æ•°æ®å¯ä¾›åˆ†æ")

        # Tab5 - æ•°æ®å¯¹æ¯”ï¼ˆåŸTAB4ï¼‰
        with tab5:
            if not bunker_df.empty:
                st.subheader("è·¨æ—¥æœŸæ•°æ®å¯¹æ¯”åˆ†æ")
                # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
                bunker_df['Date'] = pd.to_datetime(bunker_df['Date'])
                
                # æ—¥æœŸé€‰æ‹©
                date_options = bunker_df['Date'].dt.strftime('%Y-%m-%d').sort_values(ascending=False).unique()
                col1, col2 = st.columns(2)
                with col1:
                    date1 = st.selectbox("å¯¹æ¯”æ—¥æœŸ1", date_options, index=0)
                with col2:
                    date2 = st.selectbox("å¯¹æ¯”æ—¥æœŸ2", date_options, index=1 if len(date_options)>1 else 0)
                
                # æ•°æ®è·å–
                df1 = bunker_df[bunker_df['Date'].astype(str) == date1]
                df2 = bunker_df[bunker_df['Date'].astype(str) == date2]
                
                if not df1.empty and not df2.empty:
                    # æŒ‰åŒºåŸŸç”Ÿæˆå¯¹æ¯”æ•°æ®
                    comparison_data = []
                    for region_name, codes in REGION_CODE_ORDER:
                        region_ports = [PORT_CODE_MAPPING[code] for code in codes 
                                       if PORT_CODE_MAPPING[code] in bunker_df.columns]
                        for port in region_ports:
                            price1 = df1[port].values[0] if port in df1.columns else None
                            price2 = df2[port].values[0] if port in df2.columns else None
                            if price1 is not None and price2 is not None:
                                change = ((price1 - price2) / price2 * 100) if price2 != 0 else 0
                                comparison_data.append({
                                    "Region": region_name,
                                    "Port": port,
                                    date1: price1,
                                    date2: price2,
                                    "å˜åŒ–ç‡ (%)": f"{change:.2f}%"
                                })
                    
                    # æ˜¾ç¤ºå¯¹æ¯”è¡¨æ ¼
                    if comparison_data:
                        comparison_df = pd.DataFrame(comparison_data)
                        
                        # æŒ‰åŒºåŸŸåˆ†ç»„æ˜¾ç¤º
                        for region in REGION_CODE_ORDER:
                            region_name = region[0]
                            region_df = comparison_df[comparison_df['Region'] == region_name]
                            if not region_df.empty:
                                with st.expander(f"{region_name} å¯¹æ¯”æ•°æ®", expanded=True):
                                    st.dataframe(
                                        region_df.drop('Region', axis=1).set_index('Port'),
                                        use_container_width=True,
                                        height=300
                                    )
                    else:
                        st.warning("é€‰å®šæ—¥æœŸæ— æœ‰æ•ˆæ•°æ®å¯¹æ¯”")
                else:
                    st.warning("æœªæ‰¾åˆ°é€‰å®šæ—¥æœŸçš„æ•°æ®")
            else:
                st.warning("æš‚æ— æ•°æ®å¯ä¾›å¯¹æ¯”")

if __name__ == "__main__":
    main_ui()
