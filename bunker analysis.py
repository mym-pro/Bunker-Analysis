import streamlit as st
import fitz  # PyMuPDF
import pandas as pd
import os
import re
import logging
import tempfile
import time
from pathlib import Path
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from github import Github
import base64
from io import BytesIO


# --------------------------
# é…ç½®æ—¥å¿—ç³»ç»Ÿ
# --------------------------
logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger(__name__)

# --------------------------
# å¸¸é‡å®šä¹‰
# --------------------------
REGION_PORTS = {
    "Asia Pacific/Middle East": ["Singapore", "Fujairah", "Japan", "West Japan", "South Korea", 
                                 "South Korea (West)", "Hong Kong", "Shanghai", "Zhoushan", 
                                 "Sydney", "Melbourne", "Kuwait", "Khor Fakkan", "Mumbai", "Colombo"],
    "Europe": ["Algeciras", "Durban", "Gibraltar", "Malta", "Piraeus", "Rotterdam", 
               "Antwerp", "Gothenburg", "Hamburg", "Istanbul", "Las Palmas", "Novorossiisk",
               "St. Petersburg", "Lisbon", "Lome"],
    "Americas": ["Houston", "New York", "Los Angeles", "New Orleans", "Philadelphia", 
                 "Seattle", "Vancouver", "Buenos Aires", "Cartagena", "Santos", 
                 "Valparaiso", "Callao", "Guayaquil", "La Libertad", "Montevideo", 
                 "San Francisco", "Montreal*"]
}

COMPARE_PORTS = ["Singapore", "Rotterdam", "Hong Kong", "Santos", "Zhoushan"]
FUEL_TYPES = ["MLBSO00", "LNBSF00"]


class BunkerDataProcessor:
    """æ•°æ®å¤„ç†å·¥å…·ç±»"""
    
    @staticmethod
    def format_date(date_series: pd.Series) -> pd.Series:
        """ç»Ÿä¸€æ—¥æœŸæ ¼å¼ä¸ºYYYY-MM-DD"""
        return pd.to_datetime(date_series, errors='coerce').dt.date

    @staticmethod
    def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:
        """
        æ•°æ®æ¸…æ´—ï¼š
        1. è½¬æ¢æ•°å€¼åˆ—
        2. å»é™¤å…¨ä¸ºç©ºå€¼çš„åˆ—
        3. å¤„ç†å¼‚å¸¸å€¼
        """
        # æ›¿æ¢NAå¹¶å»é™¤å…¨ç©ºåˆ—
        df = df.replace('NA', pd.NA).dropna(how='all', axis=1)
        
        # æ•°å€¼ç±»å‹è½¬æ¢
        for col in df.columns:
            if col != 'Date':
                df.loc[:, col] = pd.to_numeric(df[col], errors='coerce') # éæ•°å€¼è½¬ä¸ºNaN
                
        # å»é™¤æ—¥æœŸåˆ—ä¸­çš„æ— æ•ˆæ—¥æœŸ
        if 'Date' in df.columns:
            df['Date'] = BunkerDataProcessor.format_date(df['Date'])
            df = df.dropna(subset=['Date'])
            
        return df.dropna(how='all', axis=1)

    @staticmethod
    def merge_data(existing_df: pd.DataFrame, new_df: pd.DataFrame) -> Tuple[pd.DataFrame, bool]:
        """
        æ•°æ®åˆå¹¶é€»è¾‘ï¼š
        1. åˆå¹¶æ—¶è‡ªåŠ¨å»é‡
        2. è¿”å›æ˜¯å¦æœ‰æ–°å¢æ•°æ®çš„æ ‡å¿—
        """
        if existing_df.empty:
            return new_df, True
            
        existing_dates = set(existing_df['Date'])
        new_data = new_df[~new_df['Date'].isin(existing_dates)]
        
        if new_data.empty:
            return existing_df, False
            
        return pd.concat([existing_df, new_data]).drop_duplicates().sort_values('Date').reset_index(drop=True), True

class GitHubDataManager:
    def __init__(self, token: str, repo_name: str):
        self.token = token
        self.repo_name = repo_name
        self.g = Github(self.token)
        self.repo = self.g.get_repo(self.repo_name)
    
    def read_excel(self, file_path: str) -> Tuple[pd.DataFrame, bool]:
        """ä¿®å¤è¿”å›å€¼é—®é¢˜"""
        try:
            contents = self.repo.get_contents(file_path)
            return pd.read_excel(BytesIO(base64.b64decode(contents.content)), sheet_name=0), True
        except Exception as e:
            return pd.DataFrame(), False  # æ˜ç¡®è¿”å›å…ƒç»„
    
    def save_excel(self, df: pd.DataFrame, file_path: str, commit_msg: str) -> bool:
        """ä¿å­˜Excelæ–‡ä»¶åˆ°GitHub"""
        try:
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df.to_excel(writer, index=False)
            content = output.getvalue()
            
            try:
                contents = self.repo.get_contents(file_path)
                self.repo.update_file(contents.path, commit_msg, content, contents.sha)
            except:
                self.repo.create_file(file_path, commit_msg, content)
            return True
        except Exception as e:
            logger.error(f"GitHubä¿å­˜å¤±è´¥: {str(e)}")
            return False
BUNKER_PATH = "data/bunker_prices.xlsx"
FUEL_PATH = "data/fuel_prices.xlsx"
class EnhancedBunkerPriceExtractor:
    """å¢å¼ºç‰ˆPDFæ•°æ®æå–å™¨"""
    
    def __init__(self, pdf_path: str):
        """ç§»é™¤æœ¬åœ°è·¯å¾„ä¾èµ–"""
        self.pdf_path = pdf_path

    def _validate_paths(self):
        """è·¯å¾„éªŒè¯"""
        for path in [self.bunker_path, self.fuel_path]:
            if not isinstance(path, Path):
                raise ValueError(f"æ— æ•ˆè·¯å¾„æ ¼å¼: {path} å¿…é¡»ä¸ºPathå¯¹è±¡")

    def process_pdf(self) -> Dict[str, int]:
        """
        ä¸»å¤„ç†æ–¹æ³•ï¼š
        è¿”å›åŒ…å«æ–°å¢æ•°æ®æ•°é‡çš„å­—å…¸ {'bunker': æ–°å¢æ²¹ä»·æ¡ç›®æ•°, 'fuel': æ–°å¢ç‡ƒæ–™æ¡ç›®æ•°}
        """
        try:
            doc = fitz.open(self.pdf_path)
            result = {'bunker': 0, 'fuel': 0}
            
            # å¤„ç†ç¬¬ä¸€é¡µï¼ˆæ²¹ä»·æ•°æ®ï¼‰
            bunker_df = self._process_page_1(doc[0])
            if bunker_df is not None:
                success = self._save_data(bunker_df, self.bunker_path, "BunkerPrices")
                result['bunker'] = 1 if success else 0

            # å¤„ç†ç¬¬äºŒé¡µï¼ˆç‡ƒæ–™æ•°æ®ï¼‰
            fuel_df = self._process_page_2(doc[1], bunker_df['Date'].iloc[0] if bunker_df is not None else None)
            if fuel_df is not None:
                success = self._save_data(fuel_df, self.fuel_path, "FuelPrices")
                result['fuel'] = 1 if success else 0

            doc.close()
            return result
        except Exception as e:
            logger.error(f"PDFå¤„ç†å¤±è´¥: {str(e)}")
            return {'bunker': 0, 'fuel': 0}

    def _get_page_coordinates(self, page, config: Dict) -> Optional[Dict]:
        """
        è·å–é¡µé¢å…³é”®åŒºåŸŸåæ ‡
        configç¤ºä¾‹ï¼š
        {
            'start_key': 'èµ·å§‹å…³é”®è¯',
            'end_key': 'ç»“æŸå…³é”®è¯',
            'right_boundary': 'å³ä¾§è¾¹ç•Œå…³é”®è¯',  # å¯é€‰
            'left_boundary': 'å·¦ä¾§è¾¹ç•Œå…³é”®è¯'   # å¯é€‰
        }
        """
        blocks = page.get_text("blocks")
        coords = {
            'start_y': None,
            'end_y': None,
            'left_x': 0,
            'right_x': page.rect.width
        }

        for block in blocks:
            text = block[4].strip()
            # å®šä½èµ·å§‹ä½ç½®
            if config['start_key'] in text and coords['start_y'] is None:
                coords['start_y'] = block[1]
            # å®šä½ç»“æŸä½ç½®
            if config['end_key'] in text and coords['end_y'] is None:
                coords['end_y'] = block[1]
            # å³ä¾§è¾¹ç•Œ
            if 'right_boundary' in config and config['right_boundary'] in text:
                coords['right_x'] = block[0]
            # å·¦ä¾§è¾¹ç•Œ
            if 'left_boundary' in config and config['left_boundary'] in text:
                coords['left_x'] = block[2]

        if None in [coords['start_y'], coords['end_y']]:
            logger.warning(f"é¡µé¢åæ ‡å®šä½å¤±è´¥: {config}")
            return None
        return coords

    def _process_page_1(self, page) -> Optional[pd.DataFrame]:
        """å¤„ç†æ²¹ä»·é¡µé¢"""
        # å®šä¹‰é¡µé¢è§£æé…ç½®
        coord_config = {
            'start_key': 'Bunkerwire',
            'end_key': 'Ex-Wharf',
            'right_boundary': 'Marine Fuel (PGB page 30)'
        }
        coords = self._get_page_coordinates(page, coord_config)
        if not coords:
            return None

        # æå–åŸå§‹æ–‡æœ¬
        raw_text = self._extract_text_from_area(page, coords)
        if not raw_text:
            return None

        # æå–æ—¥æœŸä¿¡æ¯
        date = self._extract_date(raw_text)
        if not date:
            return None

        # ä½¿ç”¨ä¼˜åŒ–åçš„æ­£åˆ™è¡¨è¾¾å¼æå–æ•°æ®
        pattern = re.compile(r"([A-Za-z\s\(\)-,]+)\s+([A-Z0-9]+)\s+(NA|\d+\.\d+)\s+(NANA|[+-]?\d+\.\d+)")
        start_marker = "Singapore"
        start_index = raw_text.find(start_marker)

        if start_index == -1:
            logger.warning("æœªæ‰¾åˆ°èµ·å§‹æ ‡è®° 'Singapore'ã€‚")
            return None

        mid_relevant_text = raw_text[start_index:]
        relevant_text = mid_relevant_text.replace("\n", " ").replace("\t", " ")
        relevant_text = re.sub(r"\s+", " ", relevant_text).strip() 
        matches = pattern.findall(relevant_text)
        logger.debug(f"Page 1 matches: {matches}")
        if not matches:
            logger.warning("æœªåœ¨é¡µé¢1æ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
            return None

        # æ„å»ºDataFrame
        data = {'Date': [date]}
        for port, code, price, change in matches:
            # åªä¿ç•™æœ‰æ•ˆçš„ä»·æ ¼æ•°æ®
            if price != 'NA':
                data[port.strip()] = [float(price)]
        return pd.DataFrame(data) if len(data) > 1 else None

    def _process_page_2(self, page, date) -> Optional[pd.DataFrame]:
        """å¤„ç†ç‡ƒæ–™ä»·æ ¼é¡µé¢"""
        coord_config = {
            'start_key': 'Alternative marine fuels',
            'end_key': 'Arab Gulf'
        }
        coords = self._get_page_coordinates(page, coord_config)
        if not coords:
            return None

        raw_text = self._extract_text_from_area(page, coords)
        if not raw_text:
            return None

        # æå–ç‡ƒæ–™æ•°æ®
        pattern = re.compile(r"(MLBSO00|LNBSF00)\s+(\d+\.\d+|NA)")
        matches = pattern.findall(raw_text)
        logger.debug(f"Page 2 matches: {matches}")
        if not matches:
            logger.warning("æœªåœ¨é¡µé¢2æ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
            return None

        data = {'Date': [date]} if date else {}
        for code, value in matches:
            if value != 'NA':
                data[code] = [float(value)]
        return pd.DataFrame(data) if len(data) > 1 else None

    def _extract_text_from_area(self, page, coords: Dict) -> str:
        """ä»æŒ‡å®šåŒºåŸŸæå–æ–‡æœ¬"""
        rect = fitz.Rect(
            coords['left_x'],
            min(coords['start_y'], coords['end_y']),
            coords['right_x'],
            max(coords['start_y'], coords['end_y'])
        )
        return page.get_text("text", clip=rect)

    def _extract_date(self, text: str) -> Optional[datetime.date]:
        """ä»æ–‡æœ¬ä¸­æå–æ—¥æœŸ"""
        date_pattern = r"Volume\s+\d+\s+/\s+Issue\s+\d+\s+/\s+(\w+\s+\d{1,2},\s+\d{4})"
        match = re.search(date_pattern, text)
        if not match:
            return None
        try:
            return datetime.strptime(match.group(1), "%B %d, %Y").date()
        except ValueError:
            return None

    def _save_data(self, new_df: pd.DataFrame, output_path: str, sheet_name: str) -> bool:
        # æ·»åŠ åˆ—å¯¹é½é€»è¾‘
        existing_df, exists = gh_manager.read_excel(output_path)
        if exists and not existing_df.empty:
            # å¤„ç†åˆ—ä¸ä¸€è‡´é—®é¢˜
            all_columns = list(set(existing_df.columns) | set(new_df.columns))
            existing_df = existing_df.reindex(columns=all_columns, fill_value=pd.NA)
            new_df = new_df.reindex(columns=all_columns, fill_value=pd.NA)
            combined_df = pd.concat([existing_df, new_df])
        else:
            combined_df = new_df
            
            # ä¿å­˜æ•°æ®
            return gh_manager.save_excel(
                combined_df,
                output_path,
                f"Update {sheet_name} at {datetime.now().strftime('%Y-%m-%d %H:%M')}"
            )
        except Exception as e:
            logger.error(f"ä¿å­˜å¤±è´¥: {str(e)}")
            return False


# --------------------------
# Streamlitç•Œé¢ç»„ä»¶
# --------------------------
@st.cache_data(ttl=3600, show_spinner="åŠ è½½å†å²æ•°æ®...")
def load_history_data(path: str) -> pd.DataFrame:
    """ä¿®æ”¹åçš„æ•°æ®åŠ è½½å‡½æ•°"""
    try:
        github_token = st.secrets.github.token
        repo_name = st.secrets.github.repo
        gh_manager = GitHubDataManager(github_token, repo_name)
        
        df, exists = gh_manager.read_excel(path)
        if exists:
            df['Date'] = BunkerDataProcessor.format_date(df['Date'])
            return df.sort_values('Date', ascending=False).reset_index(drop=True)
        return pd.DataFrame()
    except Exception as e:
        logger.error(f"æ•°æ®åŠ è½½å¤±è´¥: {path} - {str(e)}")
        return pd.DataFrame()

def show_status(message: str, message_type: str = "success", duration: int = 3):
    """æ˜¾ç¤ºçŠ¶æ€æç¤ºä¿¡æ¯"""
    if message_type == "success":
        st.toast(f"âœ… {message}", icon="âœ…")
    elif message_type == "warning":
        st.toast(f"âš ï¸ {message}", icon="âš ï¸")
    else:
        st.toast(f"âŒ {message}", icon="âŒ")
    time.sleep(duration)

def generate_excel_download(df: pd.DataFrame) -> bytes:
    """ç”ŸæˆExcelæ–‡ä»¶å­—èŠ‚æµï¼ˆæ·»åŠ ç©ºæ•°æ®æ ¡éªŒï¼‰"""
    if df.empty:
        raise ValueError("æ— æ³•å¯¼å‡ºç©ºæ•°æ®é›†")
    
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False)
    output.seek(0)
    return output.getvalue()

def on_download_click(success: bool, filename: str):
    """ä¸‹è½½å›è°ƒå‡½æ•°"""
    if success:
        st.toast(f"âœ… {filename} ä¸‹è½½å·²å¼€å§‹ï¼Œè¯·æŸ¥çœ‹æµè§ˆå™¨ä¸‹è½½åˆ—è¡¨")
    else:
        st.toast(f"âš ï¸ ä¸‹è½½æ–‡ä»¶ä¸ºç©ºï¼Œæœªç”Ÿæˆä¸‹è½½", icon="âš ï¸")
def main_ui():
    """ä¸»ç•Œé¢å¸ƒå±€"""
    st.set_page_config(page_title="èˆ¹ç‡ƒä»·æ ¼åˆ†æç³»ç»Ÿ", layout="wide")
    st.title(" Mariners' Bunker Price Analysis System ")

    # åˆå§‹åŒ–æ•°æ®å­˜å‚¨è·¯å¾„
    BUNKER_PATH = "data/bunker_prices.xlsx"
    FUEL_PATH = "data/fuel_prices.xlsx"

    # åˆå§‹åŒ–sessionçŠ¶æ€
    if 'processed_files' not in st.session_state:
        st.session_state.processed_files = set()
    if 'show_final_toast' not in st.session_state:
        st.session_state.show_final_toast = False

    # --------------------------
    # æ–‡ä»¶ä¸Šä¼ æ¨¡å—
    # --------------------------
    with st.expander("ğŸ“¤ ç¬¬ä¸€æ­¥ - ä¸Šä¼ PDFæŠ¥å‘Š", expanded=True):
        uploaded_files = st.file_uploader(
            "é€‰æ‹©Bunkerwire PDFæŠ¥å‘Šï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
            type=["pdf"],
            accept_multiple_files=True,
            help="è¯·ä¸Šä¼ æœ€æ–°ç‰ˆçš„Bunkerwire PDFæ–‡ä»¶"
        )

    # åªå¤„ç†æ–°ä¸Šä¼ çš„æ–‡ä»¶
    new_files = [f for f in uploaded_files if f.name not in st.session_state.processed_files]
    
    # --------------------------
    # æ•°æ®å¤„ç†é€»è¾‘
    # --------------------------
    total_added = {'bunker': 0, 'fuel': 0}
    error_messages = []
    
    if new_files:
        with st.status("æ­£åœ¨è§£ææ–‡ä»¶...", expanded=True) as status:
            for file in new_files:
                try:
                    # ...åŸæœ‰ä»£ç ...
                except Exception as e:
                    # æ·»åŠ è¯¦ç»†é”™è¯¯æ—¥å¿—
                    logger.error(f"æ–‡ä»¶å¤„ç†é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                    error_messages.append(f"âŒ {file.name} å¤„ç†å¤±è´¥: {str(e)}ï¼ˆè¯¦ç»†æ—¥å¿—è¯·æŸ¥çœ‹æ§åˆ¶å°ï¼‰")
                    # åˆ›å»ºä¸´æ—¶PDFæ–‡ä»¶
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                        tmp.write(file.getbuffer())
                        pdf_path = tmp.name

                    # å¤„ç†PDF
                    extractor = EnhancedBunkerPriceExtractor(pdf_path, [bunker_path, fuel_path])
                    result = extractor.process_pdf()
                    
                    # è®°å½•å¤„ç†ç»“æœ
                    if result['bunker'] > 0 or result['fuel'] > 0:
                        st.session_state.processed_files.add(file.name)
                        total_added['bunker'] += result['bunker']
                        total_added['fuel'] += result['fuel']
                        st.toast(f"âœ… {file.name} å¤„ç†æˆåŠŸï¼ˆ+{result['bunker']}æ²¹ä»·/+{result['fuel']}ç‡ƒæ–™ï¼‰")
                    else:
                        st.toast(f"âš ï¸ {file.name} æ— æ–°æ•°æ®ï¼ˆå¯èƒ½ä¸ºé‡å¤æ–‡ä»¶ï¼‰")

                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    os.unlink(pdf_path)

                except Exception as e:
                    error_messages.append(f"âŒ {file.name} å¤„ç†å¤±è´¥: {str(e)}")
                    logger.error(f"æ–‡ä»¶å¤„ç†é”™è¯¯: {file.name} - {str(e)}")

            # æ˜¾ç¤ºæ‰¹é‡å¤„ç†ç»“æœ
            status.update(label=f"å¤„ç†å®Œæˆï¼å…±å¤„ç†{len(new_files)}ä¸ªæ–‡ä»¶", state="complete")
            st.session_state.show_final_toast = True

        # æ˜¾ç¤ºæœ€ç»ˆæ±‡æ€»æç¤º
        if st.session_state.show_final_toast:
            final_message = []
            if total_added['bunker'] + total_added['fuel'] > 0:
                final_message.append(f"â€¢ æ–°å¢æ²¹ä»·è®°å½•: {total_added['bunker']}")
                final_message.append(f"â€¢ æ–°å¢ç‡ƒæ–™è®°å½•: {total_added['fuel']}")
            if error_messages:
                final_message.append(f"â€¢ å¤±è´¥æ–‡ä»¶: {len(error_messages)}ä¸ª")
            
            if final_message:
                st.toast("\n".join(["å¤„ç†ç»“æœæ±‡æ€»:"] + final_message), icon="ğŸ“Š")
            
            st.session_state.show_final_toast = False

        # æ¸…é™¤ç¼“å­˜ä¿è¯æ•°æ®æ›´æ–°
        st.cache_data.clear()

    # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼ˆç‹¬ç«‹æ˜¾ç¤ºï¼‰
    if error_messages:
        with st.container(border=True):
            st.error("\n\n".join(error_messages))

    # --------------------------
    # æ•°æ®åˆ†ææ¨¡å—
    # --------------------------
    bunker_df = load_history_data(bunker_path)
    fuel_df = load_history_data(fuel_path)

    with st.expander("ğŸ“ˆ ç¬¬äºŒæ­¥ - æ•°æ®åˆ†æ", expanded=True):
        tab1, tab2, tab3, tab4 = st.tabs(["æ¸¯å£æ²¹ä»·ä¿¡æ¯", "æ²¹ä»·è¶‹åŠ¿åˆ†æ", "ç‡ƒæ–™ä»·æ ¼åˆ†æ", "æ•°æ®å¯¹æ¯”"])

        with tab1:
            if not bunker_df.empty:
                st.subheader("è¿‘æœŸæ²¹ä»·è¶‹åŠ¿ï¼ˆæœ€è¿‘10ä¸ªè®°å½•ï¼‰")
                recent_data = bunker_df.head(10).copy()  # ä½¿ç”¨.copy()ç¡®ä¿ç‹¬ç«‹æ“ä½œ
                recent_data['Date'] = recent_data['Date'].astype(str)  # è½¬æ¢æ—¥æœŸåˆ—ä¸ºå­—ç¬¦ä¸²æ ¼å¼
                
                for region, ports in REGION_PORTS.items():
                    st.subheader(f"ğŸ™ï¸ {region}")
                    region_cols = [col for col in recent_data.columns if col in ports]
                    st.dataframe(
                        recent_data[["Date"] + region_cols].set_index("Date"),
                        use_container_width=True,
                        height=300,
                        hide_index=False
                    )
            else:
                st.warning("æš‚æ— æ²¹ä»·æ•°æ®å¯ä¾›åˆ†æã€‚")

        with tab2:
            if not bunker_df.empty:
                st.subheader("Multi-Port Trend Comparison")
                col1, col2 = st.columns([3, 1])
                with col1:
                    selected_ports = st.multiselect(
                        "Select Ports for Comparison",
                        [p for p in bunker_df.columns if p != 'Date'],
                        default=COMPARE_PORTS[:2]
                    )
                with col2:
                    selected_year = st.selectbox(
                        "Select Year",
                        sorted(bunker_df['Date'].apply(lambda x: x.year).unique(), reverse=True)
                    )
                filtered_df = bunker_df.loc[bunker_df['Date'].apply(lambda x: x.year) == selected_year]  # ä½¿ç”¨.loc
                if selected_ports:
                    fig = go.Figure()
                    for port in selected_ports:
                        if port in filtered_df.columns:
                            fig.add_trace(go.Scatter(
                                x=filtered_df['Date'],
                                y=filtered_df[port],
                                mode='lines+markers',
                                name=port,
                                connectgaps=True
                            ))
                    fig.update_layout(
                        title=f"Fuel Price Trends in {selected_year}",
                        xaxis_title="Date",
                        yaxis_title="Price (USD)",
                        template="plotly_white",
                        legend=dict(orientation="h", yanchor="bottom", y=1.02),
                        hovermode="x unified"
                    )
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ¸¯å£è¿›è¡Œæ¯”è¾ƒã€‚")
            else:
                st.warning("æš‚æ— æ²¹ä»·æ•°æ®å¯ä¾›åˆ†æã€‚")

        with tab3:
            if not fuel_df.empty:
                st.subheader("æ›¿ä»£ç‡ƒæ–™ä»·æ ¼è¶‹åŠ¿")
                st.dataframe(
                    fuel_df.head(10).set_index("Date"),
                    use_container_width=True
                )
                fig = go.Figure()
                for fuel_type in FUEL_TYPES:
                    fig.add_trace(go.Scatter(
                        x=fuel_df['Date'],
                        y=fuel_df[fuel_type],
                        name=fuel_type,
                        mode='lines+markers',
                        connectgaps=True
                    ))
                fig.update_layout(
                    height=600,
                    template="plotly_white",
                    yaxis_title="ä»·æ ¼ (USD/å¨)",
                    xaxis_title="æ—¥æœŸ",
                    legend=dict(orientation="h", yanchor="bottom", y=1.02),
                    hovermode="x unified"
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("æš‚æ— ç‡ƒæ–™ä»·æ ¼æ•°æ®ã€‚")

        with tab4:
            if not bunker_df.empty:
                st.subheader("æŒ‡å®šæ—¥æœŸæ¸¯å£ä»·æ ¼å¯¹æ¯”")
                date_options = sorted(bunker_df['Date'].astype(str).unique(), reverse=True)
                col1, col2 = st.columns(2)
                with col1:
                    date1 = st.selectbox("é€‰æ‹©å¯¹æ¯”æ—¥æœŸ1", date_options)
                with col2:
                    date2 = st.selectbox("é€‰æ‹©å¯¹æ¯”æ—¥æœŸ2", date_options)
                if date1 and date2:
                    df1 = bunker_df.loc[bunker_df['Date'].astype(str) == date1]  # ä½¿ç”¨.loc
                    df2 = bunker_df.loc[bunker_df['Date'].astype(str) == date2]  # ä½¿ç”¨.loc
                    if not df1.empty and not df2.empty:
                        comparison = []
                        for port in COMPARE_PORTS:
                            if port in df1.columns and port in df2.columns:
                                price1 = df1[port].values[0] if not df1[port].isna().all() else None
                                price2 = df2[port].values[0] if not df2[port].isna().all() else None
                                if price1 is not None and price2 is not None:
                                    change = ((price1 - price2) / price2 * 100) if price2 != 0 else None
                                else:
                                    change = None
                                comparison.append({
                                    "Port": port,
                                    date1: price1,
                                    date2: price2,
                                    "Change (%)": f"{change:.2f}%" if change is not None else "N/A"
                                })
                        if comparison:
                            st.dataframe(
                                pd.DataFrame(comparison).set_index("Port"),
                                use_container_width=True,
                                hide_index=False
                            )
                        else:
                            st.warning("æœªæ‰¾åˆ°é€‰å®šæ—¥æœŸçš„æ•°æ®æˆ–é€‰å®šæ¸¯å£çš„æ•°æ®ä¸å®Œæ•´ã€‚")
                    else:
                        st.warning("æœªæ‰¾åˆ°é€‰å®šæ—¥æœŸçš„æ•°æ®ã€‚")
            else:
                st.warning("æš‚æ— æ²¹ä»·æ•°æ®å¯ä¾›å¯¹æ¯”ã€‚")

    # --------------------------
    # æ•°æ®ä¸‹è½½æ¨¡å—
    # --------------------------
    with st.expander("ğŸ“¥ ç¬¬ä¸‰æ­¥ - æ•°æ®å¯¼å‡º", expanded=True):
        st.subheader("å®Œæ•´æ•°æ®ä¸‹è½½")
        col1, col2 = st.columns(2)
        with col1:
            if bunker_path.exists():
                try:
                    data = generate_excel_download(bunker_df)
                    st.download_button(
                        label="ä¸‹è½½å®Œæ•´æ²¹ä»·æ•°æ®",
                        data=data,
                        file_name="bunker_prices_full.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        on_click=lambda: on_download_click(True, "æ²¹ä»·æ•°æ®")
                    )
                except ValueError:
                    st.warning("æ²¹ä»·æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ä¸‹è½½")
                    on_download_click(False, "")
        with col2:
            if fuel_path.exists():
                try:
                    data = generate_excel_download(fuel_df)
                    st.download_button(
                        label="ä¸‹è½½å®Œæ•´ç‡ƒæ–™æ•°æ®",
                        data=data,
                        file_name="fuel_prices_full.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        on_click=lambda: on_download_click(True, "ç‡ƒæ–™æ•°æ®")
                    )
                except ValueError:
                    st.warning("ç‡ƒæ–™æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ä¸‹è½½")
                    on_download_click(False, "")

        st.subheader("å•æ—¥æ•°æ®ä¸‹è½½")
        col1, col2 = st.columns(2)
        with col1:
            if not bunker_df.empty:
                selected_bunker_date = st.selectbox(
                    "é€‰æ‹©æ²¹ä»·æ—¥æœŸ",
                    options=sorted(bunker_df['Date'].astype(str).unique(), reverse=True)
                )
                if selected_bunker_date:
                    daily_bunker = bunker_df[bunker_df['Date'].astype(str) == selected_bunker_date]
                    try:
                        data = generate_excel_download(daily_bunker)
                        st.download_button(
                            label="ä¸‹è½½å½“æ—¥æ²¹ä»·æ•°æ®",
                            data=data,
                            file_name=f"bunker_{selected_bunker_date}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            on_click=lambda: on_download_click(True, f"å½“æ—¥æ²¹ä»·æ•°æ® ({selected_bunker_date})")
                        )
                    except ValueError:
                        st.warning("å½“æ—¥æ²¹ä»·æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ä¸‹è½½")
                        on_download_click(False, "")
        with col2:
            if not fuel_df.empty:
                selected_fuel_date = st.selectbox(
                    "é€‰æ‹©ç‡ƒæ–™æ—¥æœŸ",
                    options=sorted(fuel_df['Date'].astype(str).unique(), reverse=True)
                )
                if selected_fuel_date:
                    daily_fuel = fuel_df[fuel_df['Date'].astype(str) == selected_fuel_date]
                    try:
                        data = generate_excel_download(daily_fuel)
                        st.download_button(
                            label="ä¸‹è½½å½“æ—¥ç‡ƒæ–™æ•°æ®",
                            data=data,
                            file_name=f"fuel_{selected_fuel_date}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            on_click=lambda: on_download_click(True, f"å½“æ—¥ç‡ƒæ–™æ•°æ® ({selected_fuel_date})")
                        )
                    except ValueError:
                        st.warning("å½“æ—¥ç‡ƒæ–™æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ä¸‹è½½")
                        on_download_click(False, "")

if __name__ == "__main__":
    main_ui()  
